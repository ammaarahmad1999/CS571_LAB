{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS571_LAB3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "loTrFO66UU5A"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thUTLsa1Ut1U"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/ammaarahmad1999/Naive-Bias-Spam-Classifier/main/SMSSpamCollection', sep='\\t', header=None, names =['Label', 'SMS'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1AMUnDRV6fJ",
        "outputId": "ed70c67b-555c-4074-c5b4-e1cde9f1dd85"
      },
      "source": [
        "print(df.head(10))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Label                                                SMS\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
            "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
            "6   ham  Even my brother is not like to speak with me. ...\n",
            "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
            "8  spam  WINNER!! As a valued network customer you have...\n",
            "9  spam  Had your mobile 11 months or more? U R entitle...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK0CE6MRB8Vl"
      },
      "source": [
        "#df = df.sample(frac=1, random_state=50)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOXywc1RV_Ar",
        "outputId": "4981fdb5-368f-49e6-b4c0-5db915e1ae46"
      },
      "source": [
        "print(df['Label'].value_counts())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham     4825\n",
            "spam     747\n",
            "Name: Label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCQ4UNdXW9He",
        "outputId": "65a80d4a-0fd7-441a-de07-49fb587aa1a7"
      },
      "source": [
        "length = len(df)\n",
        "print(length)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o-pJS9dyJle"
      },
      "source": [
        "def multinomial_train(df_train):\n",
        "\n",
        "  vocabulary = set()\n",
        "  for sms in df_train['SMS']:\n",
        "    for word in sms:\n",
        "        vocabulary.add(word)\n",
        "\n",
        "  word_counts_per_sms = {unique_word: [0] * len(df_train['SMS']) for unique_word in vocabulary}\n",
        "\n",
        "  for index, sms in enumerate(df_train['SMS']):\n",
        "    for word in sms:\n",
        "        word_counts_per_sms[word][index] += 1  \n",
        "  \n",
        "  word_counts = pd.DataFrame(word_counts_per_sms)\n",
        "  df_train = pd.concat([df_train, word_counts], axis=1)\n",
        "\n",
        "  # Isolating spam and ham messages first\n",
        "  spam_messages = df_train[df_train['Label'] == 'spam']\n",
        "  ham_messages = df_train[df_train['Label'] == 'ham']\n",
        "\n",
        "  # P(Spam) and P(Ham)\n",
        "  p_spam = len(spam_messages) / len(df_train)\n",
        "  p_ham = len(ham_messages) / len(df_train)\n",
        "\n",
        "  # N_Spam\n",
        "  n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
        "  n_spam = n_words_per_spam_message.sum()\n",
        "\n",
        "  # N_Ham\n",
        "  n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
        "  n_ham = n_words_per_ham_message.sum()\n",
        "\n",
        "  # N_Vocabulary\n",
        "  n_vocabulary = len(vocabulary)\n",
        "  print(f'\\tLength of vocabulary = {n_vocabulary}')\n",
        "\n",
        "  # Laplace smoothing\n",
        "  alpha = 1\n",
        "\n",
        "  # Initiate parameters\n",
        "  parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
        "  parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
        "\n",
        "  # Calculate parameters\n",
        "  for word in vocabulary:\n",
        "    n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
        "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
        "    parameters_spam[word] = p_word_given_spam\n",
        "\n",
        "    n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
        "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
        "    parameters_ham[word] = p_word_given_ham  \n",
        "  \n",
        "  return p_spam, p_ham, parameters_spam, parameters_ham, vocabulary"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGgkkg7zNYYs"
      },
      "source": [
        "def multivariate_train(df_train):\n",
        "\n",
        "  vocabulary = set()\n",
        "  for sms in df_train['SMS']:\n",
        "    for word in sms:\n",
        "        vocabulary.add(word)\n",
        "\n",
        "  word_counts_per_sms = {unique_word: [0] * len(df_train['SMS']) for unique_word in vocabulary}\n",
        "\n",
        "  for index, sms in enumerate(df_train['SMS']):\n",
        "    for word in sms:\n",
        "        word_counts_per_sms[word][index] += 1  \n",
        "  \n",
        "  word_counts = pd.DataFrame(word_counts_per_sms)\n",
        "  df_train = pd.concat([df_train, word_counts], axis=1)\n",
        "\n",
        "  # Isolating spam and ham messages first\n",
        "  spam_messages = df_train[df_train['Label'] == 'spam']\n",
        "  ham_messages = df_train[df_train['Label'] == 'ham']\n",
        "\n",
        "  # P(Spam) and P(Ham)\n",
        "  p_spam = len(spam_messages) / len(df_train)\n",
        "  p_ham = len(ham_messages) / len(df_train)\n",
        "\n",
        "  # N_Spam\n",
        "  n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
        "  n_spam = n_words_per_spam_message.sum()\n",
        "\n",
        "  # N_Ham\n",
        "  n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
        "  n_ham = n_words_per_ham_message.sum()\n",
        "\n",
        "  # N_Vocabulary\n",
        "  n_vocabulary = len(vocabulary)\n",
        "  print(f'\\tLength of vocabulary = {n_vocabulary}')\n",
        "\n",
        "  # Laplace smoothing\n",
        "  alpha = 1\n",
        "\n",
        "  # Initiate parameters\n",
        "  parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
        "  parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
        "\n",
        "  # Calculate parameters\n",
        "  for word in vocabulary:\n",
        "    n_word_given_spam = spam_messages[word].sum() # spam_messages already defined\n",
        "    p_word_given_spam = (n_word_given_spam + 1) / (len(spam_messages) + 2)\n",
        "    parameters_spam[word] = p_word_given_spam\n",
        "\n",
        "    n_word_given_ham = ham_messages[word].sum() # ham_messages already defined\n",
        "    p_word_given_ham = (n_word_given_ham + 1) / (len(ham_messages) + 2)\n",
        "    parameters_ham[word] = p_word_given_ham  \n",
        "  \n",
        "  return p_spam, p_ham, parameters_spam, parameters_ham, vocabulary"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu88VRR34L3C"
      },
      "source": [
        "def test_model(df_test, p_spam, p_ham, parameters_spam, parameters_ham, vocabulary):\n",
        "\n",
        "    correct = 0\n",
        "    total = df_test.shape[0]\n",
        "\n",
        "    for i in range(len(df_test)):\n",
        "        \n",
        "        p_spam_given_message = math.log(p_spam)\n",
        "        p_ham_given_message = math.log(p_ham)\n",
        "        message = df_test.iloc[i, 1]\n",
        "        label = df_test.iloc[i, 0]\n",
        "\n",
        "        '''for word in vocabulary:\n",
        "          if word in message:\n",
        "            \n",
        "            p_spam_given_message += math.log(parameters_spam[word])\n",
        "            p_spam_given_message += math.log(1 - parameters_spam[word])\n",
        "            \n",
        "            p_ham_given_message += math.log(parameters_ham[word])\n",
        "            p_ham_given_message += math.log(1 - parameters_ham[word])'''\n",
        "        \n",
        "        for word in message:\n",
        "          if word in parameters_spam:\n",
        "            p_spam_given_message += math.log(parameters_spam[word])\n",
        "            p_spam_given_message += math.log(1 - parameters_spam[word])\n",
        "          if word in parameters_ham:\n",
        "            p_ham_given_message += math.log(parameters_ham[word])\n",
        "            p_ham_given_message += math.log(1 - parameters_ham[word])\n",
        "        \n",
        "\n",
        "        if p_ham_given_message >= p_spam_given_message:\n",
        "            predicted = 'ham'\n",
        "        else:\n",
        "            predicted = 'spam'\n",
        "\n",
        "        if (predicted == label):\n",
        "            correct += 1\n",
        "\n",
        "    return correct/total"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfsDyb490Sni"
      },
      "source": [
        "# Divide the data set into 5 equal chunks\n",
        "size = int(len(df)/5)\n",
        "df0 = df[:size]\n",
        "df1 = df[size:2*size]\n",
        "df2 = df[2*size:3*size]\n",
        "df3 = df[3*size:4*size]\n",
        "df4 = df[4*size:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2lred7z1mLA",
        "outputId": "32f79dc9-2e0a-4919-cd98-407a96559cdb"
      },
      "source": [
        "multinomial_accuracy = []\n",
        "multivariate_accuracy = []\n",
        "\n",
        "for i in range(5):\n",
        "    print('Iteration-', i+1, ':', sep='')\n",
        "\n",
        "    if (i == 0):\n",
        "      df_train = pd.concat([df1, df2, df3, df4])\n",
        "      df_test = df0\n",
        "    if (i == 1):\n",
        "      df_train = pd.concat([df0, df2, df3, df4])\n",
        "      df_test = df1\n",
        "    if (i == 2):\n",
        "      df_train = pd.concat([df0, df1, df3, df4])\n",
        "      df_test = df2\n",
        "    if (i == 3):\n",
        "      df_train = pd.concat([df0, df1, df2, df4])\n",
        "      df_test = df3\n",
        "    if (i == 4):\n",
        "      df_train = pd.concat([df0, df1, df2, df3])\n",
        "      df_test = df4\n",
        "    \n",
        "    print('\\tSize of training set =', len(df_train))\n",
        "    print('\\tSize of testing set =', len(df_test))\n",
        "\n",
        "    #CLeaning the dataset\n",
        "    df_train['SMS'] = df_train['SMS'].str.replace('\\W', ' ') # Removes punctuation\n",
        "    df_train['SMS'] = df_train['SMS'].str.lower()            # Convert to Lowercase\n",
        "    df_train['SMS'] = df_train['SMS'].str.split()            # Split into words\n",
        "    \n",
        "    # Train, test and get the accuracy of multinomial model\n",
        "    p_spam, p_ham, parameters_spam, parameters_ham, vocabulary = multinomial_train(df_train)\n",
        "    acc  = test_model(df_test, p_spam, p_ham, parameters_spam, parameters_ham, vocabulary)\n",
        "\n",
        "    print(f'\\tAccuracy of the multinomial model = {acc}')\n",
        "    print()\n",
        "    multinomial_accuracy.append(acc)\n",
        "\n",
        "    # Train, test and get the accuracy of multinomial model\n",
        "    p_spam, p_ham, parameters_spam, parameters_ham, vocabulary = multivariate_train(df_train)\n",
        "    acc  = test_model(df_test, p_spam, p_ham, parameters_spam, parameters_ham, vocabulary)\n",
        "\n",
        "    print(f'\\tAccuracy of the multivariate model = {acc}')\n",
        "    print()\n",
        "    multivariate_accuracy.append(acc)\n",
        "\n",
        "# Print the mean accuracies of the models\n",
        "print('Mean acccuracy of multinomial model =', np.mean(multinomial_accuracy))\n",
        "print('Mean acccuracy of multivariate model =', np.mean(multivariate_accuracy))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration-1:\n",
            "\tSize of training set = 4458\n",
            "\tSize of testing set = 1114\n",
            "\tLength of vocabulary = 7806\n",
            "\tAccuracy of the multinomial model = 0.8491921005385996\n",
            "\n",
            "\tLength of vocabulary = 7806\n",
            "\tAccuracy of the multivariate model = 0.32046678635547576\n",
            "\n",
            "Iteration-2:\n",
            "\tSize of training set = 4458\n",
            "\tSize of testing set = 1114\n",
            "\tLength of vocabulary = 7762\n",
            "\tAccuracy of the multinomial model = 0.8734290843806104\n",
            "\n",
            "\tLength of vocabulary = 7762\n",
            "\tAccuracy of the multivariate model = 0.23159784560143626\n",
            "\n",
            "Iteration-3:\n",
            "\tSize of training set = 4458\n",
            "\tSize of testing set = 1114\n",
            "\tLength of vocabulary = 7775\n",
            "\tAccuracy of the multinomial model = 0.8752244165170556\n",
            "\n",
            "\tLength of vocabulary = 7775\n",
            "\tAccuracy of the multivariate model = 0.414721723518851\n",
            "\n",
            "Iteration-4:\n",
            "\tSize of training set = 4458\n",
            "\tSize of testing set = 1114\n",
            "\tLength of vocabulary = 7789\n",
            "\tAccuracy of the multinomial model = 0.8572710951526032\n",
            "\n",
            "\tLength of vocabulary = 7789\n",
            "\tAccuracy of the multivariate model = 0.5385996409335727\n",
            "\n",
            "Iteration-5:\n",
            "\tSize of training set = 4456\n",
            "\tSize of testing set = 1116\n",
            "\tLength of vocabulary = 7809\n",
            "\tAccuracy of the multinomial model = 0.8691756272401434\n",
            "\n",
            "\tLength of vocabulary = 7809\n",
            "\tAccuracy of the multivariate model = 0.517921146953405\n",
            "\n",
            "Mean acccuracy of multinomial model = 0.8648584647658024\n",
            "Mean acccuracy of multivariate model = 0.4046614286725482\n"
          ]
        }
      ]
    }
  ]
}